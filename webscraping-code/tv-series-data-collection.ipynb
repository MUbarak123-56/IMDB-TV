{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the code below and run it to go into a previous directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the codes below and run to create the directories if this is your first time running it. If it returns a statement stating that the directories already exists, proceed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%mkdir anime-series-data/\n",
    "#%mkdir anime-series-data-named/\n",
    "#%mkdir cumulative-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "from requests import get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDb Top 250 TV shows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this section is to obtain the top 250 highest rated TV shows on IMDb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TV Series List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url with the link to the top 250 highest rated TV shows list\n",
    "url = 'https://www.imdb.com/chart/toptv'\n",
    "response = get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecting info about all the tv shows from the website\n",
    "containers = tv_soup.find_all('td', class_='titleColumn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "containers_rating = tv_soup.find_all('td', class_ = \"ratingColumn imdbRating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_list = []\n",
    "for i in range(len(containers_rating)):\n",
    "    rating = containers_rating[i].strong[\"title\"]\n",
    "    rating = rating[:3]\n",
    "    rating_list.append(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listing out the encoded title of all the tv shows\n",
    "tv_list = []\n",
    "for i in range(0,len(containers)):\n",
    "    title = containers[i].a['href']\n",
    "    title = title.split(\"/\")[2]\n",
    "    tv_list.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list that extracts information about each tv such as \n",
    "# title, rating, total_votes, description, release year, its link and its encoded title\n",
    "comprehensive_list = []\n",
    "for tv in tv_list:\n",
    "    response = get('https://www.imdb.com/title/' + tv + \"/\")\n",
    "    tv_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    title_verbose = tv_soup.find('title').string\n",
    "    releaseYear = re.findall(r'[0-9][0-9][0-9][0-9]', title_verbose)\n",
    "    tv_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    #tv_title = tv_soup.find('title').string\n",
    "    #rating = tv_soup.find(\"span\", class_ = \"AggregateRatingButton__RatingScore-sc-1ll29m0-1 iTLWoV\").string\n",
    "    rating_count = tv_soup.find(\"div\", class_ =\"AggregateRatingButton__TotalRatingAmount-sc-1ll29m0-3 jkCVKJ\").string\n",
    "    tv_title = tv_soup.find(\"h1\", {\"data-testid\": \"hero-title-block__title\"}).string\n",
    "    description = tv_soup.find(\"span\", {\"data-testid\": \"plot-xl\"}).string\n",
    "    link = 'https://www.imdb.com/title/' + tv\n",
    "    encoded_title = tv\n",
    "    comprehensive_list.append([tv_title, rating_count, description, releaseYear[0], link, encoded_title])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### converting the comprehensive list into a data frame\n",
    "tv_best = pd.DataFrame(comprehensive_list, columns = [\"title\",\"total_votes\", \"description\", \"year\", \"link\", \"encoded_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_best[\"rating\"] = rating_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_best[\"rating\"] = tv_best[\"rating\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_best = tv_best[[\"title\",\"rating\",\"total_votes\", \"description\", \"year\", \"link\", \"encoded_title\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting K to 000 for total votes\n",
    "tv_best[\"total_votes\"] = tv_best[\"total_votes\"].str.replace(\"K\", \"000\")\n",
    "tv_best[\"total_votes\"] = tv_best[\"total_votes\"].str.replace(\"M\", \"000000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reseting index of data frame\n",
    "tv_best = tv_best.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a for loop to return a better result for the \n",
    "for i in range(len(tv_best)):\n",
    "    if \".\" in tv_best.loc[i, \"total_votes\"]:\n",
    "        tv_best.loc[i,\"total_votes\"] = tv_best.loc[i, \"total_votes\"][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing . with an empty string so total votes can be converted into integer\n",
    "tv_best[\"total_votes\"] = tv_best[\"total_votes\"].str.replace(\".\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming certain columns into integers\n",
    "tv_best[\"rating\"] = pd.to_numeric(tv_best[\"rating\"], downcast=\"float\")\n",
    "tv_best[\"total_votes\"] = tv_best[\"total_votes\"].astype(int)\n",
    "tv_best[\"year\"] = tv_best[\"year\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_best.to_csv(\"cumulative-data/IMDb_top_250.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting episode data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions and code were used to collect data from the TV episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tv_special(link):\n",
    "    # This function is for tv that do not have numerous seasons but rather one season.\n",
    "    # Due to their layout it is harder to obtain information about the episodes by season.\n",
    "    # Hence, it was optimal to go to the page with all the episodes in ascending order.\n",
    "    \n",
    "    # obtaining url to obtain tv info\n",
    "    url = 'https://www.imdb.com/title/' + link + \"/\"\n",
    "    response = get(url)\n",
    "    # parsing content of request\n",
    "    tv_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    # collecting title data\n",
    "    tv_title = tv_soup.find(\"h1\", {\"data-testid\": \"hero-title-block__title\"}).string\n",
    "    # collecting data of total number of episodes\n",
    "    total_episodes = int(tv_soup.find(\"span\", class_ = \"ipc-title__subtext\").text)\n",
    "    # obtaining new link for extracting tv information by episode\n",
    "    new_link = \"https://www.imdb.com/search/title/?series=\" + link + \"&view=simple&sort=release_date,asc\"\n",
    "    response = get(new_link)\n",
    "    # parsing content of request\n",
    "    tv_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    l = tv_soup.find_all(\"span\", class_ = \"lister-item-header\")\n",
    "    comprehend = []\n",
    "    episode = 0\n",
    "    season = 1\n",
    "    for u in l:\n",
    "        u = str(u)\n",
    "        # finding all tv titles\n",
    "        tv = re.findall(r'/title/tt[0-9]*/', u)\n",
    "        v = str(tv[1]).split(\"/\")[2]\n",
    "        url = 'https://www.imdb.com/title/' + v + \"/\"\n",
    "        response = get(url)\n",
    "        tv_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        # obtaining tv title\n",
    "        title = tv_soup.find(\"h1\", {\"data-testid\": \"hero-title-block__title\"}).text\n",
    "        episode += 1\n",
    "        # checking to make sure rating is not empty\n",
    "        if tv_soup.find(\"span\", class_ = \"AggregateRatingButton__RatingScore-sc-1ll29m0-1 iTLWoV\")== None:\n",
    "            rating = \"0\"\n",
    "        else:\n",
    "            # recording rating\n",
    "            rating = tv_soup.find(\"span\", class_ = \"AggregateRatingButton__RatingScore-sc-1ll29m0-1 iTLWoV\").text\n",
    "        # checking to make sure total_votes is not empty\n",
    "        if tv_soup.find(\"div\", class_ =\"AggregateRatingButton__TotalRatingAmount-sc-1ll29m0-3 jkCVKJ\") == None:\n",
    "            total_votes = \"0\"\n",
    "        else:\n",
    "            # recording total_votes\n",
    "            total_votes = tv_soup.find(\"div\", class_ =\"AggregateRatingButton__TotalRatingAmount-sc-1ll29m0-3 jkCVKJ\").text\n",
    "        # checking to make sure air date is not empty\n",
    "        if tv_soup.find(\"li\", class_ =\"ipc-inline-list__item\") == None:\n",
    "            airdate = \"\"\n",
    "        else:\n",
    "            # recording airdate\n",
    "            airdate = tv_soup.find(\"li\", class_ =\"ipc-inline-list__item\").text\n",
    "        desc = tv_soup.find(\"span\", class_ = \"GenresAndPlot__TextContainerBreakpointXL-sc-cum89p-2 eqbKRZ\").text\n",
    "        comprehend.append([tv_title, season, episode, title, airdate, rating, total_votes, desc, link])\n",
    "\n",
    "    # The while loop below is used to extend to following pages so their information can be extracted\n",
    "    n = 51\n",
    "    while n < total_episodes:\n",
    "        # obtaining urls\n",
    "        url = \"https://www.imdb.com/search/title/?series=\" + link + \"&view=simple&sort=release_date,asc&start=\" + str(n) + \"&ref_=adv_nxt\"\n",
    "        response = get(url)\n",
    "        tv_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        l = tv_soup.find_all(\"span\", class_ = \"lister-item-header\")\n",
    "        for u in l:\n",
    "            u = str(u)\n",
    "            tv = re.findall(r'/title/tt[0-9]*/', u)\n",
    "            v = str(tv[1]).split(\"/\")[2]\n",
    "            url = 'https://www.imdb.com/title/' + v + \"/\"\n",
    "            response = get(url)\n",
    "            tv_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            title = tv_soup.find(\"h1\", {\"data-testid\": \"hero-title-block__title\"}).text\n",
    "            episode += 1\n",
    "            if tv_soup.find(\"span\", class_ = \"AggregateRatingButton__RatingScore-sc-1ll29m0-1 iTLWoV\")== None:\n",
    "                rating = \"0\"\n",
    "            else:\n",
    "                rating = tv_soup.find(\"span\", class_ = \"AggregateRatingButton__RatingScore-sc-1ll29m0-1 iTLWoV\").text\n",
    "            if tv_soup.find(\"div\", class_ =\"AggregateRatingButton__TotalRatingAmount-sc-1ll29m0-3 jkCVKJ\") == None:\n",
    "                total_votes = \"0\"\n",
    "            else:\n",
    "                total_votes = tv_soup.find(\"div\", class_ =\"AggregateRatingButton__TotalRatingAmount-sc-1ll29m0-3 jkCVKJ\").text\n",
    "            if tv_soup.find(\"li\", class_ =\"ipc-inline-list__item\") == None:\n",
    "                airdate = \"\"\n",
    "            else:\n",
    "                airdate = tv_soup.find(\"li\", class_ =\"ipc-inline-list__item\").text\n",
    "            desc = tv_soup.find(\"span\", class_ = \"GenresAndPlot__TextContainerBreakpointXL-sc-cum89p-2 eqbKRZ\").text\n",
    "            comprehend.append([tv_title, season, episode, title, airdate, rating, total_votes, desc, link])\n",
    "        n += 50\n",
    "    return (comprehend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def episode_recorder(episode):\n",
    "    # This function is used for recording episodes information for tvs that have multiple seasons\n",
    "    \n",
    "    # recording episode number\n",
    "    episode_number = int(episode.meta['content'])\n",
    "    # recording episode title\n",
    "    title = episode.a['title']\n",
    "    # recording air date\n",
    "    airdate = episode.find('div', class_='airdate').text.strip()\n",
    "    # making sure the airdate value is not empty\n",
    "    if len(airdate.split(\" \")) >= 3:\n",
    "        # transforming the format of the airdate\n",
    "        new = airdate.split(\" \")\n",
    "        new = [new[1], new[0], new[2]]\n",
    "        new[1] = new[1] + \",\"\n",
    "        new = \" \".join(new)\n",
    "        airdate = new.replace(\".\", \"\")\n",
    "        new =[]\n",
    "        if episode.find('span', class_='ipl-rating-star__rating')== None:\n",
    "            rating = \"0\"\n",
    "        else:\n",
    "            rating = episode.find('span', class_='ipl-rating-star__rating').text\n",
    "        if episode.find('span', class_='ipl-rating-star__total-votes') == None:\n",
    "            total_votes = \"0\"\n",
    "        else:\n",
    "            total_votes = episode.find('span', class_='ipl-rating-star__total-votes').text\n",
    "    else:\n",
    "        airdate = \"\"\n",
    "        rating = \"0\"\n",
    "        total_votes = \"0\"\n",
    "    desc = episode.find('div', class_='item_description').text.strip()\n",
    "    return [episode_number, title, airdate, rating, total_votes, desc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tv_output(link):\n",
    "    tv_episodes = []\n",
    "    url = 'https://www.imdb.com/title/' + link + \"/\"\n",
    "    response = get(url)\n",
    "    tv_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    tv_title = tv_soup.find(\"h1\", {\"data-testid\": \"hero-title-block__title\"}).string\n",
    "    if tv_soup.find(\"select\", class_ = \"ipc-simple-select__input\")== None or tv_soup.find(\"select\", class_ = \"ipc-simple-select__input\")[\"aria-label\"][2:] != \"seasons\":\n",
    "        tv_episodes.extend(tv_special(link))\n",
    "    else: \n",
    "        n = int(tv_soup.find(\"select\", class_ = \"ipc-simple-select__input\")[\"aria-label\"][0])\n",
    "        for sn in range(1,n+1):\n",
    "            response = get('https://www.imdb.com/title/' + link + '/episodes?season=' + str(sn))\n",
    "\n",
    "            page_html = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            episode_containers = page_html.find_all('div', class_ = 'info')\n",
    "\n",
    "            \n",
    "            for episodes in episode_containers:\n",
    "                season = sn\n",
    "                #episode_number = episodes.meta['content']\n",
    "                #title = episodes.a['title']\n",
    "                #airdate = episodes.find('div', class_='airdate').text.strip()\n",
    "                #episode_data = [tv_title, season, episode_number, title, airdate, rating, total_votes, desc]\n",
    "                episode_data = [tv_title, season]\n",
    "                l = episode_recorder(episodes)\n",
    "                episode_data.extend(l)\n",
    "                episode_data.append(link)\n",
    "                tv_episodes.append(episode_data)\n",
    "    return(tv_episodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The mini dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mini dataset extracts information about the first five TV shows to showcase how the final dataset will look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing out function to make sure it can collect data about tv\n",
    "l = []\n",
    "for tv in tv_list[:5]:\n",
    "    l.extend(tv_output(tv))\n",
    "df = pd.DataFrame(l, columns = ['tv', 'season', 'episode_number', 'title', 'airdate', 'rating', 'total_votes', 'desc', 'encoded_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"airdate\"] = df[\"airdate\"].str.replace(\"Episode aired \", \"\")\n",
    "df[\"total_votes\"] = df[\"total_votes\"].str.replace(\"K\", \"000\")\n",
    "df[\"total_votes\"] = df[\"total_votes\"].str.replace(\",\", \"\")\n",
    "df[\"total_votes\"] = df[\"total_votes\"].str.replace(\"(\", \"\")\n",
    "df[\"total_votes\"] = df[\"total_votes\"].str.replace(\")\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    if \".\" in df.loc[i, \"total_votes\"]:\n",
    "        df.loc[i,\"total_votes\"] = df.loc[i, \"total_votes\"][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"total_votes\"] = df[\"total_votes\"].str.replace(\".\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming certain columns into integers\n",
    "df[\"season\"] = df[\"season\"].astype(int)\n",
    "df[\"episode_number\"] = df[\"episode_number\"].astype(int)\n",
    "df[\"rating\"] = pd.to_numeric(df[\"rating\"], downcast=\"float\")\n",
    "df[\"total_votes\"] = df[\"total_votes\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below was used to store all the datasets in different data sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = []\n",
    "count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tv in tv_list[:5]: # to obtain all the datasets, replace tv_list[:5] with tv_list\n",
    "    new_list = tv_output(tv)\n",
    "    df = pd.DataFrame(new_list, columns = ['tv', 'season', 'episode_number', 'title', 'airdate', 'rating', 'total_votes', 'desc', 'encoded_title'])\n",
    "    df[\"airdate\"] = df[\"airdate\"].str.replace(\"Episode aired \", \"\")\n",
    "    df[\"total_votes\"] = df[\"total_votes\"].str.replace(\"K\", \"000\")\n",
    "    df[\"total_votes\"] = df[\"total_votes\"].str.replace(\",\", \"\")\n",
    "    df[\"total_votes\"] = df[\"total_votes\"].str.replace(\"(\", \"\")\n",
    "    df[\"total_votes\"] = df[\"total_votes\"].str.replace(\")\", \"\")\n",
    "    for i in range(len(df)):\n",
    "        if \".\" in df.loc[i, \"total_votes\"]:\n",
    "            df.loc[i,\"total_votes\"] = df.loc[i, \"total_votes\"][:-1]\n",
    "    df[\"total_votes\"] = df[\"total_votes\"].str.replace(\".\", \"\")\n",
    "    df[\"season\"] = df[\"season\"].astype(int)\n",
    "    df[\"episode_number\"] = df[\"episode_number\"].astype(int)\n",
    "    df[\"rating\"] = pd.to_numeric(df[\"rating\"], downcast=\"float\")\n",
    "    df[\"total_votes\"] = df[\"total_votes\"].astype(int)\n",
    "    df.to_csv(\"tv-series-data/\" + tv + \".csv\", index = False)\n",
    "    # splitting the tv column into multiple columns so as to obtain tv name\n",
    "    new = df[\"tv\"].str.split(\" \", expand = True)\n",
    "    new = new.fillna(\"\")\n",
    "    word = \"-\".join(new.iloc[0,])\n",
    "    name = word.replace(\":\", \"\").strip(\"-\").lower()\n",
    "    name = name.replace(\";\", \"\")\n",
    "    name = name.replace(\"!\",\"\")\n",
    "    name = name.replace(\".\", \"\")\n",
    "    name = name.replace(\"/\", \"\")\n",
    "    name = name.replace(\"'\", \"\")\n",
    "    name = name.replace(\",\", \"\")\n",
    "    name = name.replace(\"?\", \"\")\n",
    "    if name in name_list:\n",
    "        name += str(count)\n",
    "    name_list.append(name)\n",
    "    df.to_csv(\"tv-series-data-named/\" + name + \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below combines all the anime datasets into one huge dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['tv', 'season', 'episode_number', 'title', 'airdate', 'rating', 'total_votes', 'desc', 'encoded_title'])\n",
    "for tv in tv_list: \n",
    "    if os.path.isfile(\"tv-series-data/\" + tv + \".csv\"):\n",
    "        df1 = pd.read_csv(\"tv-series-data/\" + tv + \".csv\")\n",
    "        df = pd.concat([df1, df], axis = 0)\n",
    "        df = df.reset_index(drop = True)\n",
    "df.to_csv(\"cumulative-data/tv_dataset.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
